{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CitiBike ML Demo\n",
    "By: David Stearns  \n",
    "  \n",
    "This demo (while fully functional *could use a bit of clean up!* :D ) demonstrates Snowpark Python's capability to build, train, and deploy machine learning models. It uses the Scalar UDF function which is great for single predictions, however, if you would like to do full table predictions or use input batches, the best way to accomplish that is to use Vectorized UDF's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark\n",
    "from snowflake.snowpark.functions import sproc\n",
    "from snowflake.snowpark.functions import udf\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import *\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "import math\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark import Window\n",
    "pd.set_option('display.max_columns', None)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import credentials\n",
    "import io\n",
    "import joblib\n",
    "import cachetools\n",
    "conn = {\n",
    "    \"account\": credentials.credentials[\"account\"],\n",
    "    \"user\": credentials.credentials[\"username\"],\n",
    "    \"password\": credentials.credentials[\"password\"],\n",
    "    \"role\": credentials.credentials[\"role\"],\n",
    "    \"warehouse\": credentials.credentials[\"warehouse\"],\n",
    "    \"database\": credentials.credentials[\"database\"],\n",
    "    \"schema\": credentials.credentials[\"schema\"]\n",
    "}\n",
    "session = Session.builder.configs(conn).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(session, model, path):\n",
    "  input_stream = io.BytesIO()\n",
    "  joblib.dump(model, input_stream)\n",
    "  session._conn._cursor.upload_stream(input_stream, path)\n",
    "  return \"successfully created file: \" + path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Stage area CITIBIKE_ML successfully created.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(f\"create or replace stage citibike_ml\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_hourly = session.table(\"trips_stations_vw\")\n",
    "df_trips_daily = df_trips_hourly.select(F.to_date(F.col(\"STARTTIME\")).as_(\"ds\")).groupBy(F.col(\"ds\")).count().select(F.col(\"ds\"), F.col(\"COUNT\").as_(\"y\"))\n",
    "df_weather = session.table(\"weather_vw\")\n",
    "df_trips_weather = df_trips_daily.join(df_weather, df_trips_daily[\"DS\"] == df_weather[\"OBSERVATION_DATE\"])\\\n",
    "                    .select(F.col(\"DS\"),F.col(\"Y\"), F.col(\"TEMP_AVG_C\"), F.col(\"TOT_PRECIP_IN\"))\n",
    "df_trips_weather = df_trips_weather.withColumn(\"rain_indicator\", F.when(F.col(\"TOT_PRECIP_IN\") > 0, F.lit(1) ).otherwise(F.lit(0)))\n",
    "df_trips_weather = df_trips_weather.sort(F.col(\"DS\"))\n",
    "df_trips_weather.select(\"DS\", \"Y\", \"RAIN_INDICATOR\", \"TEMP_AVG_C\").write.mode(\"overwrite\").save_as_table(\"citibike_ml_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_packages('snowflake-snowpark-python', 'scikit-learn', 'pandas', 'numpy', 'joblib', 'cachetools')\n",
    "def citibike_ml_demo(session: snowflake.snowpark.Session) -> str:\n",
    "\n",
    "    import snowflake.snowpark as snp\n",
    "    from snowflake.snowpark import functions as F\n",
    "    from snowflake.snowpark import types as T\n",
    "\n",
    "    model_name = \"predict_trips\"\n",
    "    stage_name = \"citibike_ml\"\n",
    "    df = session.table(\"citibike_ml_demo\")\n",
    "    pandas_df = df.toPandas()\n",
    "    pandas_df[\"trips_yesterday\"] = pandas_df['Y'].shift(1)\n",
    "    pandas_df[\"Y_log\"] = np.log(pandas_df[\"Y\"])\n",
    "    pandas_df[\"trips_yesterday_log\"] = np.log(pandas_df[\"trips_yesterday\"])\n",
    "    pandas_df = pandas_df[1:]\n",
    "\n",
    "    X = pandas_df[[\"RAIN_INDICATOR\", \"TEMP_AVG_C\", \"trips_yesterday_log\"]]\n",
    "    y = pandas_df[[\"Y_log\"]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33 )\n",
    "    rf = RandomForestRegressor(n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    save_model(session, rf, f\"@{stage_name}/{model_name}.joblib\")\n",
    "\n",
    "    model_name_full = session.sql(f\"ls @{stage_name}\").collect()[0][0]\n",
    "\n",
    "    performance = cross_validate(rf, X, y, cv=3)\n",
    "\n",
    "    return f\"Created model: {model_name_full}.... Performance Metrics: {performance}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering my SPROC within Snowflake\n",
    "train_rfc_model = session.sproc.register(citibike_ml_demo, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Created model: citibike_ml/predict_trips.joblib.............. {'fit_time': array([0.14057446, 0.13836741, 0.13778305]), 'score_time': array([0.01067162, 0.01074004, 0.01069951]), 'test_score': array([0.67073652, 0.61245731, 0.65127835])}\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the SPROC for model training\n",
    "train_rfc_model(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing my model into the session\n",
    "session.add_import(\"@citibike_ml/predict_trips.joblib\")  \n",
    "\n",
    "# Caching my model so it is only read once\n",
    "@cachetools.cached(cache={})\n",
    "\n",
    "# Function to read the model file into another function\n",
    "def read_file(filename):\n",
    "       import os\n",
    "       import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "       if import_dir:\n",
    "              with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "                     m = joblib.load(file)\n",
    "                     return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering the UDF\n",
    "@udf(session=session, name=\"predict_trips\", is_permanent=True, stage_location=\"@citibike_ml\", replace=True)\n",
    "def predict_trips(args: list) -> int:\n",
    "    m = read_file('predict_trips.joblib')\n",
    "    if isinstance(m, str):\n",
    "        return m\n",
    "    return m.predict([args])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 24343 trips yesterday\n",
      "Based on the inputs: \n",
      " RAIN = 0, TEMP(C) = 22, TRIPS YESTERDAY = 24343\n",
      "....\n",
      "There will be 8103 trips today.\n"
     ]
    }
   ],
   "source": [
    "# create a prediction\n",
    "# inputs are: RAIN(1/0), TEMP(in C), TRIPS YESTERDAY(natural log)\n",
    "# the trips_yesterday variable has to be in the form of a natural log\n",
    "# you can change these variables if you want... but it doesn't matter\n",
    "\n",
    "trips_yesterday_log = 10.1\n",
    "rain = 0\n",
    "temp = 22\n",
    "\n",
    "trips_yesterday = math.floor(np.exp(10.1))\n",
    "print(f\"There were {trips_yesterday} trips yesterday\")\n",
    "trips_predicted_today = math.floor(session.sql(f\"select exp(predict_trips([{rain}, {temp}, {trips_yesterday_log}]))\").collect()[0][0])\n",
    "print(f\"Based on the inputs: \\n RAIN = {rain}, TEMP(C) = {temp}, TRIPS YESTERDAY = {trips_yesterday}\\n....\\nThere will be {trips_predicted_today} trips today.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('snowpark_demos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61aef635fca093b00ca00b2731ed2b6a94ed91192af7cb2d724f77a96c850456"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
